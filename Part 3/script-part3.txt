# By Sara Del Rio (srio@decsai.ugr.es)

#######################################Caso Práctico 2#######################################

#Ejecutar todo como user: hadoop
#1. Crear el directorio de entrada “/user/hadoop/datasets/iris” en HDFS:

hadoop fs -mkdir /user/hadoop/datasets /user/hadoop/datasets/iris  

#2. Mover los conjuntos de datos al directorio creado previamente en HDFS:

hadoop fs -put *.arff datasets/iris

############# Caso de estudio: 5 maps – 10 árboles #############

#3. Generar el fichero que describe al conjunto de datos

hadoop jar /home/hadoop/mahout-distribution-0.9.jar org.apache.mahout.classifier.df.tools.Describe -p datasets/iris/iris-5-1tra.arff -f datasets/iris/iris-5-1tra.info -d 4 N L

#4. Ejecutar la aplicación  

hadoop jar /home/hadoop/mahout-distribution-0.9.jar org.apache.mahout.classifier.df.mapreduce.BuildForest -Dmapreduce.input.fileinputformat.split.minsize=728 -Dmapreduce.input.fileinputformat.split.maxsize=728 -o output_iris_5maps -d datasets/iris/iris-5-1tra.arff -ds datasets/iris/iris-5-1tra.info -sl 3 -p -t 10

#5. Usar el modelo generado en el paso anterior para clasificar nuevos datos

hadoop jar /home/hadoop/mahout-distribution-0.9.jar org.apache.mahout.classifier.df.mapreduce.TestForest -i datasets/iris/iris-5-1tst.arff -ds datasets/iris/iris-5-1tra.info -m output_iris_5maps -a -mr -o predictions_iris_5maps

#6. Comprobar la salida (las 10 primeras predicciones)

hadoop fs -cat predictions_iris_5maps/iris-5-1tst.arff.out | head

############# Caso de estudio: 10 maps – 10 árboles #############

#7. Ejecutar la aplicación  

hadoop jar /home/hadoop/mahout-distribution-0.9.jar org.apache.mahout.classifier.df.mapreduce.BuildForest -Dmapreduce.input.fileinputformat.split.minsize=364 -Dmapreduce.input.fileinputformat.split.maxsize=364 -o output_iris_10maps -d datasets/iris/iris-5-1tra.arff -ds datasets/iris/iris-5-1tra.info -sl 3 -p -t 10

#8. Usar el modelo generado en el paso anterior para clasificar nuevos datos

hadoop jar /home/hadoop/mahout-distribution-0.9.jar org.apache.mahout.classifier.df.mapreduce.TestForest -i datasets/iris/iris-5-1tst.arff -ds datasets/iris/iris-5-1tra.info -m output_iris_10maps -a -mr -o predictions_iris_10maps

#9. Comprobar la salida (las 10 primeras predicciones)

hadoop fs -cat predictions_iris_10maps/iris-5-1tst.arff.out | head

############# Caso de estudio: 1 map – 10 árboles #############

#10. Ejecutar la aplicación  

hadoop jar /home/hadoop/mahout-distribution-0.9.jar org.apache.mahout.classifier.df.mapreduce.BuildForest -Dmapreduce.input.fileinputformat.split.minsize=3640 -Dmapreduce.input.fileinputformat.split.maxsize=3640 -o output_iris_1map -d datasets/iris/iris-5-1tra.arff -ds datasets/iris/iris-5-1tra.info -sl 3 -p -t 10

#11. Usar el modelo generado en el paso anterior para clasificar nuevos datos

hadoop jar /home/hadoop/mahout-distribution-0.9.jar org.apache.mahout.classifier.df.mapreduce.TestForest -i datasets/iris/iris-5-1tst.arff -ds datasets/iris/iris-5-1tra.info -m output_iris_1map -a -mr -o predictions_iris_1map

#12. Comprobar la salida (las 10 primeras predicciones)

hadoop fs -cat predictions_iris_1map/iris-5-1tst.arff.out | head
